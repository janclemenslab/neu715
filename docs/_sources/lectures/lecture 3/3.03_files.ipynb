{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3.3 - Working with files\n",
    "Experimental data is saved in a bunch of files - often one file per animal or experiment. If you want to analyse the data with python you need to:\n",
    "1. Discover and list these data files, so you can process each of them automatically in a for loop.\n",
    "2. Read the data in the files into python variables for later manipulation.\n",
    "\n",
    "Say we have experimental data stored in the following directory structure:\n",
    "```\n",
    "experiments\n",
    "├── experiment_1\n",
    "│   ├── final_behavioral_scores.txt\n",
    "│   └── initial_behavioral_scores.txt\n",
    "├── experiment_2\n",
    "│   ├── final_behavioral_scores.txt\n",
    "│   └── initial_behavioral_scores.txt\n",
    "├── information.txt\n",
    "└── mouse_names.txt\n",
    "```\n",
    "\n",
    "A bit of nomenclature: Take this path `experiments/experiment_1/final_behavioral_scores.txt`\n",
    "- `final_behavioral_scores.txt` is the file name, `final_behavioral_scores` is called the file stem, `.txt` is called the suffix or extension\n",
    "- `experiments` and `experiment_1` are directories or folders. `experiments` is the parent directory of `experiment_1`. `experiment_1` is  a subdirectory of `experiments`\n",
    "- `/` is the path separator. On windows it can also be `\\`. The system specific path separator can be obtained throug `os.sep`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.sep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discovering files\n",
    "\n",
    "The [glob](https://docs.python.org/3/library/glob.html) module allows you to list files in a directory.\n",
    "\n",
    "_Wild card_ characters allow you to find file names matching a specific pattern:\n",
    "- `?` matches individual characters\n",
    "- `*` matches any string of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glob('experiments/*')=['experiments/experiment_1', 'experiments/information.txt', 'experiments/mouse_names.txt', 'experiments/experiment_2']\n",
      "glob('experiments/*.txt')=['experiments/information.txt', 'experiments/mouse_names.txt']\n",
      "glob('experiments/i*.txt')=['experiments/information.txt']\n",
      "glob('experiments/*/')=['experiments/experiment_1/', 'experiments/experiment_2/']\n",
      "glob('experiments/*/*.txt')=['experiments/experiment_1/initial_behavioral_scores.txt', 'experiments/experiment_1/final_behavioral_scores.txt', 'experiments/experiment_2/initial_behavioral_scores.txt', 'experiments/experiment_2/final_behavioral_scores.txt']\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "print(f\"{glob('experiments/*')=}\")  # find all files and directories in the experiments directory\n",
    "print(f\"{glob('experiments/*.txt')=}\")  # find files ending in '.txt'\n",
    "print(f\"{glob('experiments/i*.txt')=}\")  # find files and directories in 'experiments', starting with 'i', and ending in '.txt'\n",
    "\n",
    "print(f\"{glob('experiments/*/')=}\")  # find all subdirectories\n",
    "print(f\"{glob('experiments/*/*.txt')=}\")  # find 'txt' files in all subdirectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating paths\n",
    "We often need to manipulate path names.\n",
    "\n",
    "Say we want to process the data in `initial_behavioral_scores.txt` and `final_behavioral_scores.txt` for each experiment in `experiments`, and want to save the results in a folder called `results` that mimics the structure of the data folder: `results/experiment_1/behavior.xls`, `results/experiment_2/behavior.xls`\n",
    "\n",
    "We want to generate the paths for the new results files automatically from the paths of the data files. That means we need to manipulate the path names. In one exercise, you will do just that!!\n",
    "\n",
    "There are two ways of working with paths in python\n",
    "- [os.path](https://docs.python.org/3/library/os.path.html) (old)\n",
    "- [pathlib](https://docs.python.org/3/library/pathlib.html) (new but more complicated - we won't cover it here)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os.path.splitext(path)=('updir/subdir/name', '.txt')\n",
      "path='updir/subdir/name.txt', trunk='updir/subdir/name', extension='.txt'\n",
      "os.path.split(path)=('updir/subdir', 'name.txt')\n",
      "path.split('/')=['updir', 'subdir', 'name.txt']\n",
      "os.path.basename(path)='name.txt'\n",
      "os.path.dirname(path)='updir/subdir'\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "path = 'updir/subdir/name.txt'\n",
    "print(f\"{os.path.splitext(path)=}\")\n",
    "path_parts = os.path.splitext(path)\n",
    "trunk = path_parts[0]\n",
    "extension = path_parts[1]\n",
    "print(f\"{path=}, {trunk=}, {extension=}\")\n",
    "\n",
    "# this will split off the file name from the rest of the path:\n",
    "print(f\"{os.path.split(path)=}\")\n",
    "\n",
    "# we can treat path as a string and use the \"split\" function to split the string at a specified sign - in this case the path separator\n",
    "print(f\"{path.split('/')=}\")\n",
    "\n",
    "print(f\"{os.path.basename(path)=}\")\n",
    "\n",
    "print(f\"{os.path.dirname(path)=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now know how to split a path in various ways. How can we assemble the parts into something new?\n",
    "\n",
    "If the parts are strings, we can use the `+` operator to concatenate them. This will create a file name with a new suffix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old path: updir/subdir/name.txt\n",
      "new path: updir/subdir/name.mp3\n"
     ]
    }
   ],
   "source": [
    "print(f\"old path: {path}\")\n",
    "path_parts = os.path.splitext(path)\n",
    "trunk = path_parts[0]\n",
    "extension = path_parts[1]\n",
    "\n",
    "new_extension = '.mp3'\n",
    "new_path = trunk + new_extension\n",
    "print(f\"new path: {new_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating directories\n",
    "To save files to new directories, we can create them directly with python:\n",
    "\n",
    "`os.makedirs('tmp/sub1/sub2', exist_ok=True)`\n",
    "\n",
    "`exist_ok=True` prevents an error if the directory already exists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading data from files\n",
    "\n",
    "- Text files: `.txt` or `.csv`\n",
    "- Excel files ending in `.xls` or `.xlsx`\n",
    "- Matlab files ending in `.mat`\n",
    "- Numpy files ending in `.npy`, `.npz`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from text files\n",
    "Data in text files is typically saved as a single column of data - with one value per row/line and a column label:\n",
    "```csv\n",
    "Responses\n",
    "0.561\n",
    "0.342\n",
    "0.23\n",
    "0.144\n",
    "```\n",
    "Tabular data with multiple columns is saved with a specific character separating the individual columns in a row: the _delimiter_. Common delimiters are `,` (csv - comma-sparated values), `;`, or `\\tab`.\n",
    "```csv\n",
    "Time,Responses\n",
    "1,0.561\n",
    "2,0.342\n",
    "3,0.23\n",
    "4,0.144\n",
    "```\n",
    "\n",
    "We can use numpy or the [pandas library](https://pandas.pydata.org) for loading and saving data. Numpy and pandas are numerical computation packages, and come with function for data IO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string 'Responses' to float64 at row 0, column 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Responses'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/mouse1.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/neu715/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:1397\u001b[0m, in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(delimiter, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1395\u001b[0m     delimiter \u001b[38;5;241m=\u001b[39m delimiter\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1397\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1398\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1399\u001b[0m \u001b[43m            \u001b[49m\u001b[43munpack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munpack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1400\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[0;32m~/miniconda3/envs/neu715/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:1036\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[1;32m   1033\u001b[0m     data \u001b[38;5;241m=\u001b[39m _preprocess_comments(data, comments, encoding)\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read_dtype_via_object_chunks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1036\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43m_load_from_filelike\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1038\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimaginary_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimaginary_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiplines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilelike\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilelike\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbyte_converters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbyte_converters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;66;03m# This branch reads the file into chunks of object arrays and then\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     \u001b[38;5;66;03m# casts them to the desired actual dtype.  This ensures correct\u001b[39;00m\n\u001b[1;32m   1047\u001b[0m     \u001b[38;5;66;03m# string-length and datetime-unit discovery (like `arr.astype()`).\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m     \u001b[38;5;66;03m# Due to chunking, certain error reports are less clear, currently.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filelike:\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string 'Responses' to float64 at row 0, column 1."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.loadtxt('data/mouse1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the file and inspect it! Can you guess the cause of the error?\n",
    "\n",
    "This is how to solve it. Check the documentation to understand what the `skiprows` argument does. A good google query is the package name followed by the function name: \"numpy loadtxt\" or straight \"np.loadtxt\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  2.  3.  4.  5. 56.  6.] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "np_data = np.loadtxt('data/mouse1.txt', skiprows=1)\n",
    "print(np_data, type(np_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving data to text files\n",
    "We can use numpy to save any numpy array to a text file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [1.3, 2.2, 3.5, 4.8]\n",
    "np.savetxt('test.txt', data, header='Responses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from excel files\n",
    "We can use the pandas library to load `xls` or `xlsx` files. Pandas loads data not into a list or a dictionary but has it's own data type - the `DataFrame`. We will learn next week how to work with `DataFrames`. For now, we can easily convert the data from the `DataFrame` to a list or a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('data/mouse_data.xls', sheet_name=\"Mouse1\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the type of df?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of df is <class 'pandas.core.frame.DataFrame'>.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The type of df is {type(df)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't really know yet what to do with a `DataFrame` - so let's convert it to a numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1],\n",
       "       [ 2],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [ 5],\n",
       "       [ 6],\n",
       "       [ 7],\n",
       "       [ 8],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [11],\n",
       "       [12],\n",
       "       [13],\n",
       "       [14],\n",
       "       [15]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_numpy()  # to a numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from matlab files\n",
    "- old format: `scipy.io.loadmat(filename)` ([docs](https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.loadmat.html))\n",
    "- new format: Open as an hdf5 file using h5py ([docs](https://docs.h5py.org/en/stable/quick.html)) \n",
    "\n",
    "Both will open the file as a dictionary, with variable names as keys and the data as values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from numpy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NpzFile 'dummy.npz' with keys: data, names"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.load('dummy.npz')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading data to/from a text file\n",
    "\n",
    "- Text files: `.txt` or `.csv`\n",
    "- Excel files ending in `.xls` or `.xlsx`\n",
    "- Numpy files ending in `.npy`, `.npz`\n",
    "\n",
    "### Saving data to text files\n",
    "`np.loadtxt` loads data from a text file - guess what `np.savetxt` does! `np.savetxt` will use the `,` as the default delimiter, but you can change that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = [1,2,3]\n",
    "filename = 'dummy.txt'\n",
    "np.savetxt(filename, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and loading data to/from non-text files\n",
    "For large datasets - think hours of multi-channel electrophyiology recordings - text files become very big and slow to work with. In that case, we can save data directly as binary, non-text data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdummy.npy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39msave(filename, data)\n\u001b[1;32m      3\u001b[0m np\u001b[38;5;241m.\u001b[39mload(filename)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "filename = 'dummy.npy'\n",
    "np.save(filename, data)\n",
    "np.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also save multiple variables to the same file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is this? NpzFile 'dummy.npz' with keys: data, names. Check the docs for np.load!\n",
      "as a list: list(file_contents.keys())=['data', 'names']\n",
      "file_contents['names']=array('data_new', dtype='<U8')\n"
     ]
    }
   ],
   "source": [
    "filename = 'dummy.npz'\n",
    "data_new = ['alpha', 'beta', 'gamma', 'epsilon']\n",
    "np.savez(filename, data=data, names='data_new')\n",
    "\n",
    "file_contents = np.load(filename)\n",
    "print(f\"What is this? {file_contents}. Check the docs for np.load!\")\n",
    "print(f\"as a list: {list(file_contents.keys())=}\")\n",
    "print(f\"{file_contents['names']=}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neu715",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
