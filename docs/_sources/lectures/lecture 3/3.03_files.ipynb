{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with files\n",
    "Experimental data is saved in a bunch of files - often one file per animal or experiment. If you want to analyse the data with python you need to:\n",
    "1. Discover and list these data files, so you can process each of them automatically in a for loop.\n",
    "2. Read the data in the files into python variables for later manipulation.\n",
    "\n",
    "Say we have experimental data stored in the following directory structure:\n",
    "```\n",
    "experiments\n",
    "├── experiment_1\n",
    "│   ├── final_behavioral_scores.txt\n",
    "│   └── initial_behavioral_scores.txt\n",
    "├── experiment_2\n",
    "│   ├── final_behavioral_scores.txt\n",
    "│   └── initial_behavioral_scores.txt\n",
    "├── information.txt\n",
    "└── mouse_names.txt\n",
    "```\n",
    "\n",
    "A bit of nomenclature: Take this path `experiments/experiment_1/final_behavioral_scores.txt`\n",
    "- `final_behavioral_scores.txt` is the file name, `final_behavioral_scores` is called the file stem, `.txt` is called the suffix or extension\n",
    "- `experiments` and `experiment_1` are directories or folders. `experiments` is the parent directory of `experiment_1`. `experiment_1` is  a subdirectory of `experiments`\n",
    "- `/` is the path separator. On windows it can also be `\\`. The system specific path separator can be obtained throug `os.sep`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.sep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discovering files\n",
    "\n",
    "The [glob](https://docs.python.org/3/library/glob.html) module allows you to list files in a directory.\n",
    "\n",
    "_Wild card_ characters allow you to find file names matching a specific pattern:\n",
    "- `?` matches individual characters\n",
    "- `*` matches any string of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glob('experiments/*')=['experiments/experiment_1', 'experiments/information.txt', 'experiments/mouse_names.txt', 'experiments/experiment_2']\n",
      "glob('experiments/*.txt')=['experiments/information.txt', 'experiments/mouse_names.txt']\n",
      "glob('experiments/i*.txt')=['experiments/information.txt']\n",
      "glob('experiments/*/')=['experiments/experiment_1/', 'experiments/experiment_2/']\n",
      "glob('experiments/*/*.txt')=['experiments/experiment_1/initial_behavioral_scores.txt', 'experiments/experiment_1/final_behavioral_scores.txt', 'experiments/experiment_2/initial_behavioral_scores.txt', 'experiments/experiment_2/final_behavioral_scores.txt']\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "print(f\"{glob('experiments/*')=}\")  # find all files and directories in the dat directory\n",
    "print(f\"{glob('experiments/*.txt')=}\")  # find files ending in '.txt'\n",
    "print(f\"{glob('experiments/i*.txt')=}\")  # find files and directories in 'dat', starting with 'm', and ending in '.txt'\n",
    "\n",
    "print(f\"{glob('experiments/*/')=}\")  # find all subdirectories\n",
    "print(f\"{glob('experiments/*/*.txt')=}\")  # find 'txt' files in all subdirectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating paths\n",
    "We often need to manipulate path names.\n",
    "\n",
    "Say we want to process the data in `initial_behavioral_scores.txt` and `final_behavioral_scores.txt` for each experiment in `experiments`, and want to save the results in a folder called `results` that mimics the structure of the data folder: `results/experiment_1/behavior.xls`, `results/experiment_2/behavior.xls`\n",
    "\n",
    "We want to generate the paths for the new results files automatically from the paths of the data files. That means we need to manipulate the path names. In one exercise, you will do just that!!\n",
    "\n",
    "There are two ways of working with paths in python\n",
    "- [os.path](https://docs.python.org/3/library/os.path.html) (old)\n",
    "- [pathlib](https://docs.python.org/3/library/pathlib.html) (new but more complicated - we won't cover it here)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common way of manipulating paths is via the `os.path` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os.path.splitext(path)=('updir/subdir/name', '.txt')\n",
      "path='updir/subdir/name.txt', trunk='updir/subdir/name', extension='.txt'\n",
      "os.path.split(path)=('updir/subdir', 'name.txt')\n",
      "path.split('/')=['updir', 'subdir', 'name.txt']\n",
      "os.path.basename(path)='name.txt'\n",
      "os.path.dirname(path)='updir/subdir'\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "path = 'updir/subdir/name.txt'\n",
    "print(f\"{os.path.splitext(path)=}\")\n",
    "path_parts = os.path.splitext(path)\n",
    "trunk = path_parts[0]\n",
    "extension = path_parts[1]\n",
    "print(f\"{path=}, {trunk=}, {extension=}\")\n",
    "\n",
    "# this will split off the file name from the rest of the path:\n",
    "print(f\"{os.path.split(path)=}\")\n",
    "\n",
    "# we can treat path as a string and use the \"split\" function to split the string at a specified sign - in this case the path separator\n",
    "print(f\"{path.split('/')=}\")\n",
    "\n",
    "print(f\"{os.path.basename(path)=}\")\n",
    "\n",
    "print(f\"{os.path.dirname(path)=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now know how to split a path in various ways. How can we assemble the parts into something new?\n",
    "\n",
    "If the parts are strings, we can use the `+` operator to concatenate them. This will create a file name with a new suffix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old path: updir/subdir/name.txt\n",
      "new path: updir/subdir/name.mp3\n"
     ]
    }
   ],
   "source": [
    "print(f\"old path: {path}\")\n",
    "path_parts = os.path.splitext(path)\n",
    "trunk = path_parts[0]\n",
    "extension = path_parts[1]\n",
    "\n",
    "new_extension = '.mp3'\n",
    "new_path = trunk + new_extension\n",
    "print(f\"new path: {new_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating directories\n",
    "To save files to new directories, we can create them directly with python:\n",
    "\n",
    "`os.makedirs('tmp/sub1/sub2', exist_ok=True)`\n",
    "\n",
    "`exist_ok=True` prevents an error if the directory already exists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data from files into python\n",
    "\n",
    "- Text files: `.txt` or `.csv`\n",
    "- Excel files ending in `.xls` or `.xlsx`\n",
    "- Matlab files ending in `.mat`\n",
    "- Data files ending in `.npy`, `.npz`, or `.h5`\n",
    "- Video/audio (later)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from text files\n",
    "Data in text files is typically saved as a single column of data - with one value per row/line\n",
    "\n",
    "Tabular data with multiple columns is saved with a specific character separating the individual columns in a row: the _delimiter_. Common delimiters are `,` (csv - comma-sparated values), `;`, or `\\tab`.\n",
    "\n",
    "We can use numpy or pandas for loading and saving data. Numpy and pandas are numerical computation packages, and come with function for data IO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string 'Responses' to float64 at row 0, column 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Responses'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/janc/Library/CloudStorage/Dropbox/_teaching/neu715/neu715/lectures/lecture 3/3.03_files.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/janc/Library/CloudStorage/Dropbox/_teaching/neu715/neu715/lectures/lecture%203/3.03_files.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/janc/Library/CloudStorage/Dropbox/_teaching/neu715/neu715/lectures/lecture%203/3.03_files.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mloadtxt(\u001b[39m'\u001b[39;49m\u001b[39mdata/mouse1.txt\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/neu715/lib/python3.12/site-packages/numpy/lib/npyio.py:1373\u001b[0m, in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(delimiter, \u001b[39mbytes\u001b[39m):\n\u001b[1;32m   1371\u001b[0m     delimiter \u001b[39m=\u001b[39m delimiter\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mlatin1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1373\u001b[0m arr \u001b[39m=\u001b[39m _read(fname, dtype\u001b[39m=\u001b[39;49mdtype, comment\u001b[39m=\u001b[39;49mcomment, delimiter\u001b[39m=\u001b[39;49mdelimiter,\n\u001b[1;32m   1374\u001b[0m             converters\u001b[39m=\u001b[39;49mconverters, skiplines\u001b[39m=\u001b[39;49mskiprows, usecols\u001b[39m=\u001b[39;49musecols,\n\u001b[1;32m   1375\u001b[0m             unpack\u001b[39m=\u001b[39;49munpack, ndmin\u001b[39m=\u001b[39;49mndmin, encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m   1376\u001b[0m             max_rows\u001b[39m=\u001b[39;49mmax_rows, quote\u001b[39m=\u001b[39;49mquotechar)\n\u001b[1;32m   1378\u001b[0m \u001b[39mreturn\u001b[39;00m arr\n",
      "File \u001b[0;32m~/miniconda3/envs/neu715/lib/python3.12/site-packages/numpy/lib/npyio.py:1016\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     data \u001b[39m=\u001b[39m _preprocess_comments(data, comments, encoding)\n\u001b[1;32m   1015\u001b[0m \u001b[39mif\u001b[39;00m read_dtype_via_object_chunks \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1016\u001b[0m     arr \u001b[39m=\u001b[39m _load_from_filelike(\n\u001b[1;32m   1017\u001b[0m         data, delimiter\u001b[39m=\u001b[39;49mdelimiter, comment\u001b[39m=\u001b[39;49mcomment, quote\u001b[39m=\u001b[39;49mquote,\n\u001b[1;32m   1018\u001b[0m         imaginary_unit\u001b[39m=\u001b[39;49mimaginary_unit,\n\u001b[1;32m   1019\u001b[0m         usecols\u001b[39m=\u001b[39;49musecols, skiplines\u001b[39m=\u001b[39;49mskiplines, max_rows\u001b[39m=\u001b[39;49mmax_rows,\n\u001b[1;32m   1020\u001b[0m         converters\u001b[39m=\u001b[39;49mconverters, dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1021\u001b[0m         encoding\u001b[39m=\u001b[39;49mencoding, filelike\u001b[39m=\u001b[39;49mfilelike,\n\u001b[1;32m   1022\u001b[0m         byte_converters\u001b[39m=\u001b[39;49mbyte_converters)\n\u001b[1;32m   1024\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1025\u001b[0m     \u001b[39m# This branch reads the file into chunks of object arrays and then\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m     \u001b[39m# casts them to the desired actual dtype.  This ensures correct\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m     \u001b[39m# string-length and datetime-unit discovery (like `arr.astype()`).\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m     \u001b[39m# Due to chunking, certain error reports are less clear, currently.\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m     \u001b[39mif\u001b[39;00m filelike:\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string 'Responses' to float64 at row 0, column 1."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.loadtxt('data/mouse1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the file and inspect it! Can you guess the cause of the error?\n",
    "\n",
    "This is how to solve it. Check the documentation to understand what the `spikrows` argument does. A good google query is the package name followed by the function name: \"numpy loadtxt\" or straight \"np.loadtxt\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  2.  3.  4.  5. 56.  6.] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "np_data = np.loadtxt('data/mouse1.txt', skiprows=1)\n",
    "print(np_data, type(np_data))\n",
    "responses = list(np_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from excel files\n",
    "We can use the pandas library to load `xls` or `xlsx` files. Pandas loads data not into a list or a dictionary but has it's own data type - the `DataFrame`. We will learn next week how to work with `DataFrames`. For now, we can easily convert the data from the `DataFrame` to a list or a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Responses\n",
       "0           1\n",
       "1           2\n",
       "2           3\n",
       "3           4\n",
       "4           5\n",
       "5           6\n",
       "6           7\n",
       "7           8\n",
       "8           9\n",
       "9          10\n",
       "10         11\n",
       "11         12\n",
       "12         13\n",
       "13         14\n",
       "14         15"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('data/mouse_data.xls', sheet_name=\"Mouse1\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the type of df?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of df is <class 'pandas.core.frame.DataFrame'>.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The type of df is {type(df)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't really know yet what to do with a `DataFrame` - so let's convert it to a numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1],\n",
       "       [ 2],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [ 5],\n",
       "       [ 6],\n",
       "       [ 7],\n",
       "       [ 8],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [11],\n",
       "       [12],\n",
       "       [13],\n",
       "       [14],\n",
       "       [15]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_numpy()  # to a numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from matlab files\n",
    "- old format: `scipy.io.loadmat(filename)` ([docs](https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.loadmat.html))\n",
    "- new format: Open as an hdf5 file using h5py ([docs](https://docs.h5py.org/en/stable/quick.html)) \n",
    "\n",
    "Both will open the file as a dictionary, with variable names as keys and the data as values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving data to a file\n",
    "\n",
    "- Text files: `.txt` or `.csv`\n",
    "- Excel files ending in `.xls` or `.xlsx`\n",
    "- Data files ending in `.npy`, `.npz`, or `.h5`\n",
    "\n",
    "### Saving data to text files\n",
    "`np.loadtxt` loads data from a text file - guess what `np.savetxt` does! `np.loadtxt` will use the `,` as the default delimiter, but you can change that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = [1,2,3]\n",
    "filename = 'dummy.txt'\n",
    "np.savetxt(filename, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving data to non-text files\n",
    "For large datasets - think hours of multi-channel electrophyiology recordings - text files become very big and slow to work with. In that case, we can save data directly as binary, non-text data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'dummy.npy'\n",
    "np.save(filename, data)\n",
    "np.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also save multiple variables to the same file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is this? NpzFile 'dummy.npz' with keys: data, names. Check the docs for np.load!\n",
      "as a list: list(file_contents.keys())=['data', 'names']\n",
      "file_contents['names']=array('data_new', dtype='<U8')\n"
     ]
    }
   ],
   "source": [
    "filename = 'dummy.npz'\n",
    "data_new = ['alpha', 'beta', 'gamma', 'epsilon']\n",
    "np.savez(filename, data=data, names='data_new')\n",
    "\n",
    "file_contents = np.load(filename)\n",
    "print(f\"What is this? {file_contents}. Check the docs for np.load!\")\n",
    "print(f\"as a list: {list(file_contents.keys())=}\")\n",
    "print(f\"{file_contents['names']=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5\n",
    "\n",
    "hdf5 files are another common file format for binary (non-text) storage. \n",
    "Like npz files, hdf5 files have a dictionary-like interface.\n",
    "\n",
    "For more details, see the [docs](https://docs.h5py.org/en/stable/quick.html)."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7ea0ec616133ead53c1908c8f6539f5c0cb9b2f78368e2bb6ab3f847e89ca400"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
