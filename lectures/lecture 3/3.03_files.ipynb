{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with files\n",
    "Experimental data is saved in a bunch of files - often one file per animal or experiment. If you want to analyse the data for several animals or experiments with python you need to:\n",
    "1. Discover and list these data files, so you can process each of them automatically in a for loop.\n",
    "2. Read the data in the files into python variables for later manipulation and save the results stored in python variables to results files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and saving data to/from files\n",
    "\n",
    "- Text files: `.txt` or `.csv`\n",
    "- Excel files ending in `.xls` or `.xlsx`\n",
    "- Matlab files ending in `.mat`\n",
    "- Numpy files ending in `.npy`, `.npz`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from text files\n",
    "Data in text files is often saved as a single column of data - with one value per row/line and sometimes with a column label:\n",
    "```csv\n",
    "Responses\n",
    "0.561\n",
    "0.342\n",
    "0.23\n",
    "0.144\n",
    "```\n",
    "Tabular data with multiple columns is saved with a specific character separating the individual columns in a row: the _delimiter_. Common delimiters are `,` (csv - comma-sparated values), `;`, or `\\tab`.\n",
    "```csv\n",
    "Time,Responses\n",
    "1,0.561\n",
    "2,0.342\n",
    "3,0.23\n",
    "4,0.144\n",
    "```\n",
    "\n",
    "We can use numpy or the [pandas library](https://pandas.pydata.org) for loading and saving data. Numpy and pandas are numerical computation packages, and come with function for data IO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string 'Responses' to float64 at row 0, column 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Responses'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[67], line 2\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/mouse1.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/miniconda3/envs/neu715/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:1397\u001b[0m, in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n",
      "\u001b[1;32m   1394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(delimiter, \u001b[38;5;28mbytes\u001b[39m):\n",
      "\u001b[1;32m   1395\u001b[0m     delimiter \u001b[38;5;241m=\u001b[39m delimiter\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;32m-> 1397\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1398\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1399\u001b[0m \u001b[43m            \u001b[49m\u001b[43munpack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munpack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1400\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "\n",
      "File \u001b[0;32m~/miniconda3/envs/neu715/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:1036\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n",
      "\u001b[1;32m   1033\u001b[0m     data \u001b[38;5;241m=\u001b[39m _preprocess_comments(data, comments, encoding)\n",
      "\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read_dtype_via_object_chunks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m-> 1036\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43m_load_from_filelike\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m   1037\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquote\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1038\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimaginary_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimaginary_unit\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1039\u001b[0m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiplines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1040\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1041\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilelike\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilelike\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1042\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbyte_converters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbyte_converters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m   1045\u001b[0m     \u001b[38;5;66;03m# This branch reads the file into chunks of object arrays and then\u001b[39;00m\n",
      "\u001b[1;32m   1046\u001b[0m     \u001b[38;5;66;03m# casts them to the desired actual dtype.  This ensures correct\u001b[39;00m\n",
      "\u001b[1;32m   1047\u001b[0m     \u001b[38;5;66;03m# string-length and datetime-unit discovery (like `arr.astype()`).\u001b[39;00m\n",
      "\u001b[1;32m   1048\u001b[0m     \u001b[38;5;66;03m# Due to chunking, certain error reports are less clear, currently.\u001b[39;00m\n",
      "\u001b[1;32m   1049\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filelike:\n",
      "\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string 'Responses' to float64 at row 0, column 1."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.loadtxt('data/mouse1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the file and inspect it! Can you guess the cause of the error?\n",
    "\n",
    "This is because numpy wants to load the data into an array, but does not know how to deal with the column title in the text file (open the file in a text editor to check). We can skip the column header in the first row of the file using the `skiprows` keyword argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  2.  3.  4.  5. 56.  6.] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "np_data = np.loadtxt('data/mouse1.txt', skiprows=1)\n",
    "print(np_data, type(np_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving data to text files\n",
    "We can use numpy to save any numpy array to a text file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [1.3, 2.2, 3.5, 4.8]\n",
    "np.savetxt('test.txt', data, header='Responses')  # the \"header\" argument is optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from excel files\n",
    "We can use the pandas library to load `xls` or `xlsx` files. Pandas loads data not into a list or a dictionary but has it's own data type - the `DataFrame`. For now, we can easily convert the data from a `DataFrame` to a list or a numpy array.\n",
    "\n",
    "__Caution:__ Depending on the format of the excel file, you may need to install an additional package ('xlrd') to be able to load the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Responses\n",
       "0           1\n",
       "1           2\n",
       "2           3\n",
       "3           4\n",
       "4           5\n",
       "5           6\n",
       "6           7\n",
       "7           8\n",
       "8           9\n",
       "9          10\n",
       "10         11\n",
       "11         12\n",
       "12         13\n",
       "13         14\n",
       "14         15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "excel_data = pd.read_excel('data/mouse_data.xls', sheet_name=\"Mouse1\")\n",
    "excel_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the type of `excel_data`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of df is <class 'pandas.core.frame.DataFrame'>.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The type of df is {type(excel_data)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not cover `DataFrame` here. But we can easily convert the DataFrame to a numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1],\n",
       "       [ 2],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [ 5],\n",
       "       [ 6],\n",
       "       [ 7],\n",
       "       [ 8],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [11],\n",
       "       [12],\n",
       "       [13],\n",
       "       [14],\n",
       "       [15]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "excel_data.to_numpy()  # to a numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from matlab files\n",
    "- old format: `scipy.io.loadmat(filename)` ([docs](https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.loadmat.html))\n",
    "- new format: Open as an hdf5 file using h5py ([docs](https://docs.h5py.org/en/stable/quick.html)) \n",
    "\n",
    "Both will open the file as a dictionary, with variable names as keys and the data as values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving data to numpy files\n",
    "A more efficient (faster load/save, less disk space) format is the numpy file. There are two ways of saving data to numpy files.\n",
    "\n",
    "You can save a single variable using the `np.save`. The resulting file should have the extension `npy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "time = np.array([1, 2, 3, 4])\n",
    "print(time)\n",
    "np.save('saved_single_variable.npy', time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load the variabe from the file using `np.load`. Since the file only contained a single variable, `np.load` will return the values of the variable directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loaded_npy = np.load('saved_single_variable.npy')\n",
    "loaded_npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also save multiple variables to a single file using `np.savez`, which will create a file with the extension `npz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_to_save = np.array([1, 2, 3, 4])\n",
    "voltage_to_save = np.array([-60, -60, 40, -60])\n",
    "np.savez('saved_multiple_variables.npz', time=time_to_save, voltage=voltage_to_save)  # the keywords \"time\" and \"voltage\" will be the names associated with the saved data variables.\n",
    "np.savez('saved_multiple_variables_NO.npz', time_to_save, voltage_to_save)  # the keywords \"time\" and \"voltage\" will be the names associated with the saved data variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading an `npz` files will return a dictionary-like data structure, with the names of the saved variables as keys and the variables' data as values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NpzFile 'saved_multiple_variables.npz' with keys: time, voltage\n",
      "time: [1 2 3 4]\n",
      "Variable \"time\" with values \"[1 2 3 4]\".\n",
      "Variable \"voltage\" with values \"[-60 -60  40 -60]\".\n"
     ]
    }
   ],
   "source": [
    "loaded_npz = np.load('saved_multiple_variables.npz')\n",
    "print(loaded_npz)\n",
    "\n",
    "print(\"time:\", loaded_npz['time'])\n",
    "\n",
    "for key, val in loaded_npz.items():\n",
    "    print(f'Variable \"{key}\" with values \"{val}\".')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discovering files\n",
    "If we have data from multiple experiments or animals, we want to automatically process everything with python.\n",
    "To do that we need to find a way to find out what files are on our computer and where they are so we can load them.\n",
    "\n",
    "Say we have experimental data stored in the following directory structure:\n",
    "```\n",
    "experiments\n",
    "├── experiment_1\n",
    "│   ├── final_behavioral_scores.txt\n",
    "│   └── initial_behavioral_scores.txt\n",
    "├── experiment_2\n",
    "│   ├── final_behavioral_scores.txt\n",
    "│   └── initial_behavioral_scores.txt\n",
    "├── information.txt\n",
    "└── mouse_names.txt\n",
    "```\n",
    "\n",
    "A bit of nomenclature: Take this path `experiments/experiment_1/final_behavioral_scores.txt`\n",
    "- `final_behavioral_scores.txt` is the file name, `final_behavioral_scores` is called the file stem, `.txt` is called the suffix or extension\n",
    "- `experiments` and `experiment_1` are directories or folders. `experiments` is the parent directory of `experiment_1`. `experiment_1` is  a subdirectory of `experiments`\n",
    "- `/` is the path separator.\n",
    "\n",
    "The [glob](https://docs.python.org/3/library/glob.html) module allows you to list directories or files in a directory.\n",
    "\n",
    "_Wild card_ characters allow you to find file names matching a specific pattern:\n",
    "- `?` matches individual characters\n",
    "- `*` matches any string of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glob('experiments/*')=['experiments/experiment_1', 'experiments/information.txt', 'experiments/mouse_names.txt', 'experiments/experiment_2']\n",
      "glob('experiments/*.txt')=['experiments/information.txt', 'experiments/mouse_names.txt']\n",
      "glob('experiments/i*.txt')=['experiments/information.txt']\n",
      "glob('experiments/experiment_?')=['experiments/experiment_1', 'experiments/experiment_2']\n",
      "glob('experiments/*/')=['experiments/experiment_1/', 'experiments/experiment_2/']\n",
      "glob('experiments/*/*.txt')=['experiments/experiment_1/initial_behavioral_scores.txt', 'experiments/experiment_1/final_behavioral_scores.txt', 'experiments/experiment_2/initial_behavioral_scores.txt', 'experiments/experiment_2/final_behavioral_scores.txt']\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "print(f\"{glob('experiments/*')=}\")  # find all files and directories in the experiments directory\n",
    "print(f\"{glob('experiments/*.txt')=}\")  # find files ending in '.txt'\n",
    "print(f\"{glob('experiments/i*.txt')=}\")  # find files and directories in 'experiments', starting with 'i', and ending in '.txt'\n",
    "print(f\"{glob('experiments/experiment_?')=}\")  # find files and directories in 'experiments', starting with 'experiment_', and ending in a single unknown character.\n",
    "\n",
    "print(f\"{glob('experiments/*/')=}\")  # find all subdirectories\n",
    "print(f\"{glob('experiments/*/*.txt')=}\")  # find 'txt' files in all subdirectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating paths\n",
    "We often need to manipulate path names.\n",
    "\n",
    "Say we want to process the data in `initial_behavioral_scores.txt` and `final_behavioral_scores.txt` for each experiment in `experiments`, and want to save the results in a folder called `results` that mimics the structure of the data folder: `results/experiment_1/behavior.xls`, `results/experiment_2/behavior.xls`.\n",
    "\n",
    "We want to generate the paths for the new results files automatically from the paths of the data files. That means we need to manipulate the path names. In one exercise, you will do just that!!\n",
    "\n",
    "There are two ways of working with paths in python\n",
    "- [os.path](https://docs.python.org/3/library/os.path.html) (old)\n",
    "- [pathlib](https://docs.python.org/3/library/pathlib.html) (new but more complicated - we won't cover it here)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os.path.splitext(my_path)=('parentdir/subdir/name', '.txt')\n",
      "my_path='parentdir/subdir/name.txt', trunk='parentdir/subdir/name', extension='.txt'\n",
      "trunk='parentdir/subdir', head='name.txt'\n",
      "new_trunk='parentdir', new_head='subdir'\n",
      "os.path.basename(my_path)='name.txt'\n",
      "os.path.dirname(my_path)='parentdir/subdir'\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "my_path = 'parentdir/subdir/name.txt'\n",
    "\n",
    "print(f\"{os.path.splitext(my_path)=}\")\n",
    "my_path_parts = os.path.splitext(my_path)\n",
    "trunk = my_path_parts[0]\n",
    "extension = my_path_parts[1]\n",
    "print(f\"{my_path=}, {trunk=}, {extension=}\")\n",
    "\n",
    "# this will split off the file name from the rest of the path:\n",
    "trunk, head = os.path.split(my_path)\n",
    "print(f\"{trunk=}, {head=}\")\n",
    "\n",
    "# we can split the trunk again to split off the sub directory\n",
    "new_trunk, new_head = os.path.split(trunk)\n",
    "print(f\"{new_trunk=}, {new_head=}\")\n",
    "\n",
    "print(f\"{os.path.basename(my_path)=}\")  # returns the filename\n",
    "print(f\"{os.path.dirname(my_path)=}\")  # returns the directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now know how to split a path in various ways. How can we assemble the parts into something new?\n",
    "\n",
    "We can use `os.path.join` with multiple strings as arguments to join them into a new path. This function will use the correct path separator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory_name/subdirectory_name/file_name.ext\n"
     ]
    }
   ],
   "source": [
    "new_path = os.path.join('directory_name', 'subdirectory_name', 'file_name.ext')\n",
    "print(new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to change the file extension? \n",
    "Say our data file is an excel file (extension '.xlsx') and we want to save the results from analyzing that file to a text file (extension '.txt'). \n",
    "\n",
    "Since the parts are strings, we can use the `+` operator to concatenate them. This will create a file name with a new suffix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data from mouse_276.xls\n",
      "Save result to mouse_276.txt\n"
     ]
    }
   ],
   "source": [
    "data_file_name = 'mouse_276.xls'\n",
    "print('Load data from', data_file_name)\n",
    "\n",
    "# First split off the old extension:\n",
    "data_file_trunk, data_file_ext = os.path.splitext(data_file_name)\n",
    "\n",
    "# Then add the new extension to the file trunk\n",
    "results_file_name = data_file_trunk + '.txt'\n",
    "print('Save result to', results_file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating directories\n",
    "To save files to new directories, we can create them directly with python:\n",
    "\n",
    "`os.makedirs('tmp/sub1/sub2', exist_ok=True)`\n",
    "\n",
    "`exist_ok=True` prevents an error if the directory already exists."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
